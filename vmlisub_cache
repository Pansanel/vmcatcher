#!/usr/bin/env python
import sys
if sys.version_info < (2, 4):
    print "Your python interpreter is too old. Please consider upgrading."
    sys.exit(1)

if sys.version_info < (2, 5):
    import site
    import os.path
    from distutils.sysconfig import get_python_lib
    found = False
    module_dir = get_python_lib()
    for name in os.listdir(module_dir):
        lowername = name.lower()
        if lowername[0:10] == 'sqlalchemy' and 'egg' in lowername:
            sqlalchemy_dir = os.path.join(module_dir, name) 
            if os.path.isdir(sqlalchemy_dir):
                site.addsitedir(sqlalchemy_dir) 
                found = True
                break
    if not found:
        print "Could not find SQLAlchemy installed."
        sys.exit(1)

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

import hepixvmlis.databaseDefinition as model
import os.path
import logging
import optparse
import smimeX509validation.loadcanamespace as loadcanamespace
from hepixvmlis.__version__ import version
import hepixvmlis
import urllib2
import urllib
import hashlib
import datetime
from hepixvmitrust.vmitrustlib import VMimageListDecoder as VMimageListDecoder
from hepixvmitrust.vmitrustlib import time_format_definition as time_format_definition
from hepixvmitrust.vmitrustlib import file_extract_metadata as file_extract_metadata
import os, statvfs 
try:
    import simplejson as json
except:
    import json
from urlparse import urlparse

class cache_manager(object):
    def __init__(self,SessionFactory, dir_cache, dir_partial, dir_expired):
        self.log = logging.getLogger("db_controler")
        self.SessionFactory = SessionFactory
        
        self.dir_cache = dir_cache
        self.dir_partial = dir_partial
        self.dir_expired = dir_expired
        self.file_cache_index = os.path.join(self.dir_cache,"cache.idx")
        self.cache_index_load()
        self.files = {}
    def cache_index_load(self):
        if os.path.isfile(self.file_cache_index):
            fp = open(self.file_cache_index,'r')
            lines = fp.read()
            tmp = json.loads(lines)
            if type(tmp) is dict:
                self.files = tmp
    def cache_index_save(self):
        fp = open(self.file_cache_index,'w')
        fp.write(json.dumps(self.files))
        fp.flush()
        fp.close()

    
    def check_checksum(self):
        files_to_delete = []
        for filename in self.files.keys():
            filepath = os.path.join(self.dir_cache,filename)
            if not os.path.isfile(filename):
                files_to_delete.append(filepath)
                continue
            file_metadata = file_extract_metadata(filepath)
            print file_metadata
        for filename in files_to_delete:
            filepath = os.path.join(self.dir_cache,filename)
            os.remove(filepath)
    def download_images(self):
        Session = self.SessionFactory()
        query_image = Session.query(model.Subscription,model.Imagelist,model.Image).\
                filter(model.Subscription.authorised == True).\
                filter(model.Subscription.imagelist_latest == model.Imagelist.id).\
                filter(model.Image.imagelist == model.Imagelist.id)
                #.\
                #filter(model.Imagelist.authorised == True)
        for touple in query_image:
            subscription, imagelist, image = touple
            downloadneeded = True
            for path in self.files.keys():
                downloaded_hash = self.files[path]
                if downloaded_hash == image.sha512:
                    downloadneeded = False
                    break
            if downloadneeded:
                
                filename = os.path.join(self.dir_partial,image.identifier)
                stats = os.statvfs(self.dir_partial) 
                if image.size > (stats[statvfs.F_BSIZE] * stats[statvfs.F_BAVAIL]):
                    self.log.error("Image '%s' is too large" % (image.identifier))
                    continue
                urltouple = urlparse(image.uri)
                if urltouple.scheme == u'http':
                    req = urllib2.urlopen(image.uri)
                    CHUNK = 16 * 1024
                    try:
                        fp = open(filename, 'wb')
                        while True:
                            chunk = req.read(CHUNK)
                            if not chunk: break
                            fp.write(chunk)
                    finally:
                        fp.flush()
                        fp.close()
                file_metadata = file_extract_metadata(filename)
                if (int(file_metadata[u'hv:size']) == int(image.size) and
                    file_metadata[u'hv:size'] == image.sha512):
                    print "downloaded"
                else:
                    os.remove(filename)
                    print "downlaod failed"
def main():
    log = logging.getLogger("vmlisub_sub.main")
    """Runs program and handles command line options"""
    p = optparse.OptionParser(version = "%prog " + version)
    p.add_option('-d', '--database', action ='store', help='Database Initiation string',
        default='sqlite:///tutorial.db')
    p.add_option('-c', '--cert-dir', action ='store',help='Certificate directory.', metavar='INPUTDIR',
        default='/etc/grid-security/certificates/')
    p.add_option('-C', '--cache-dir', action ='store',help='Set the cache directory.',metavar='INPUTDIR')
    p.add_option('-p', '--partial-dir', action ='store',help='Set the cache download directory.')
    p.add_option('-e', '--expired-dir', action ='store',help='Set the cache expired directory.')
    options, arguments = p.parse_args()
    
    dir_cache = None
    dir_partial = None
    dir_expired = None
    
    
    if options.cache_dir:
        dir_cache = options.cache_dir
    if options.partial_dir:
        dir_partial = options.partial_dir
    if options.expired_dir:
        dir_expired = options.expired_dir
    
    if dir_cache == None:
        dir_cache = "."
    if dir_partial == None:
        dir_partial = os.path.join(dir_cache,"partial")
    if dir_expired == None:
        dir_expired = os.path.join(dir_cache,"expired")
    
    engine = create_engine(options.database, echo=False)
    model.init(engine)
    SessionFactory = sessionmaker(bind=engine)
    fred = cache_manager(SessionFactory,dir_cache, dir_partial, dir_expired)
    fred.cache_index_save()
    fred.download_images()
    
            


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    main()
